# 2.2_–∫–ª—é—á–µ–≤—ã–µ_—Å–ª–æ–≤–∞.py

import nltk
from nltk.corpus import stopwords
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from sklearn.feature_extraction.text import CountVectorizer

# 1. –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
RESULT_CSV = "nyt_2024_news_sentiment_deberta-v3-small_turbo.csv"

# 2. –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
all_news_df = pd.read_csv(RESULT_CSV, parse_dates=['published_date'])

# 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è sentiment
all_news_df['sentiment'] = all_news_df['sentiment'].astype(str).str.strip().str.lower()

# 4. –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤
nltk.download('stopwords', quiet=True)
stop_words = set(stopwords.words('english'))

# 5. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
def preprocess_text(text):
    if not isinstance(text, str):
        return ""
    words = text.lower().split()
    words = [w for w in words if w.isalpha() and w not in stop_words]
    return ' '.join(words)

all_news_df['clean_text'] = all_news_df['full_text'].apply(preprocess_text)

# 6. –§—É–Ω–∫—Ü–∏—è –±–∏–≥—Ä–∞–º–º
def get_top_bigrams(texts, n=30):
    texts = texts.dropna().str.strip()
    texts = texts[texts != '']
    if texts.empty:
        return []
    vec = CountVectorizer(ngram_range=(2,2), stop_words='english')
    X = vec.fit_transform(texts)
    if X.shape[1] == 0:
        return []
    counts = X.sum(axis=0).A1
    terms = vec.get_feature_names_out()
    return sorted(zip(terms, counts), key=lambda x: x[1], reverse=True)[:n]

def safe_get_top_bigrams(texts, label):
    cnt = texts.dropna().str.strip().shape[0]
    if cnt == 0:
        print(f"‚ö†Ô∏è –ù–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è {label} ({cnt} –∑–∞–ø–∏—Å–µ–π).")
        return []
    return get_top_bigrams(texts)

# 7. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
positive = all_news_df.loc[all_news_df['sentiment']=='positive', 'clean_text']
neutral  = all_news_df.loc[all_news_df['sentiment']=='neutral',  'clean_text']
negative = all_news_df.loc[all_news_df['sentiment']=='negative', 'clean_text']

# 8. –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-10 –±–∏–≥—Ä–∞–º–º –∫–∞–∂–¥–æ–≥–æ
top_pos = safe_get_top_bigrams(positive, "positive")[:10]
top_neu = safe_get_top_bigrams(neutral,  "neutral") [:10]
top_neg = safe_get_top_bigrams(negative, "negative")[:10]

print("üî• –¢–æ–ø-10 –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –±–∏–≥—Ä–∞–º–º:", top_pos)
print("üòê –¢–æ–ø-10 –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö –±–∏–≥—Ä–∞–º–º:", top_neu)
print("üíÄ –¢–æ–ø-10 –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –±–∏–≥—Ä–∞–º–º:", top_neg)

# 9. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ WordCloud
def generate_wordcloud(bigrams, title):
    if not bigrams:
        print(f"‚ö†Ô∏è –ù–µ—Ç –±–∏–≥—Ä–∞–º–º –¥–ª—è {title}.")
        return
    text = ' '.join([t for t,_ in bigrams])
    wc = WordCloud(width=800, height=400, background_color='white').generate(text)
    plt.figure(figsize=(10,5))
    plt.imshow(wc, interpolation='bilinear')
    plt.title(f'WordCloud: {title}')
    plt.axis('off')
    plt.show()

generate_wordcloud(top_pos, "Positive News")
generate_wordcloud(top_neu, "Neutral News")
generate_wordcloud(top_neg, "Negative News")
